!pip install scikit-learn
!pip install seaborn
!pip install sklearn
import sklearn.preprocessing
!pip install --upgrade pip
!pip install apto


# Dataset

df = pd.read_csv("/content/AEP_hourly.csv")
print("="*50)
print("First Five Rows ","\n")
print(df.head(2),"\n")
print("="*50)
print("Information About Dataset","\n")
print(df.info(),"\n")
print("="*50)
print("Describe the Dataset ","\n")
print(df.describe(),"\n")
print("="*50)
print("Null Values t ","\n")
print(df.isnull().sum(),"\n")


#Extracting Features from Dataset

# Extract all Data Like Year MOnth Day Time etc
dataset = df
dataset["Month"] = pd.to_datetime(df["Datetime"]).dt.month
dataset["Year"] = pd.to_datetime(df["Datetime"]).dt.year
dataset["Date"] = pd.to_datetime(df["Datetime"]).dt.date
dataset["Time"] = pd.to_datetime(df["Datetime"]).dt.time
dataset["Week"] = pd.to_datetime(df["Datetime"]).dt.week
dataset["Day"] = pd.to_datetime(df["Datetime"]).dt.day_name()
dataset = df.set_index("Datetime")
dataset.index = pd.to_datetime(dataset.index)
dataset.head(1)

print(df.Year.unique(),"/n")
print("Total NUmber of Unique Year", df.Year.nunique(), "/n")


# Data Visualization

from matplotlib import style
fig = plt.figure()
axl = plt.subplot2grid((1,1), (0,0))
style.use('ggplot')
sns.lineplot(x=dataset["Year"], y=dataset["AEP_MW"], data=df)
sns.set(rc={'figure.figsize' :(15,6)})
plt.title("Energy consumption in year 2004")
plt.xlabel("Date")
plt.ylabel("Energy in MW")
plt.grid(True)
plt.legend()
for label in axl.xaxis.get_ticklabels():
  label.set_rotation(90)
plt.title("Energy Consumption According to Year")


# Energy Consumption Each Year

from matplotlib import style
fig = plt.figure()
ax1= fig.add_subplot(311)
ax2= fig.add_subplot(312)
ax3= fig.add_subplot(313)
style.use('ggplot')
y_2004 = dataset["2004"]["AEP_MW"].to_list()
x_2004 = dataset["2004"]["Date"].to_list()
ax1.plot(x_2004,y_2004, color="green", linewidth=1.7)
y_2005 = dataset["2005"]["AEP_MW"].to_list()
x_2005 = dataset["2005"]["Date"].to_list()
ax2.plot(x_2005, y_2005, color="green", linewidth=1)
y_2006 = dataset["2006"]["AEP_MW"].to_list()
x_2006 = dataset["2006"]["Date"].to_list()
ax3.plot(x_2006, y_2006, color="green", linewidth=1)
plt.rcParams["figure.figsize"] = (18,8)
plt.title("Energy consumptionnin")
plt.xlabel("Date")
plt.ylabel("Energy in MW")
plt.grid(True, alpha=1)
plt.legend()
for label in ax1.xaxis.get_ticklabels():
    label.set_rotation(90)


# Energy Distribution

sns.distplot(dataset["AEP_MW"])
plt.title("Energy Distribution")


# Energy with Respect to TIme

# Check the dataset for the 'DateTime' column.
print(dataset.columns)

import datetime

dataset['Date'] = pd.to_datetime(dataset['Date'])

dataset['Time'] = dataset['Time'].astype(str)

dataset['Date'] = pd.to_datetime(dataset['Date'])
dataset['Time'] = pd.to_datetime(dataset['Time'])

dataset['DateTime'] = dataset['Date'] + pd.to_timedelta(dataset['Time'].dt.strftime('%H:%M:%S'))

import pandas as pd
# Assuming 'Date' and 'Time' columns are already in datetime format
# If not, convert them to datetime first using pd.to_datetime()
# Convert 'Date' column to string format
dataset['Date'] = dataset['Date'].dt.strftime('%Y-%m-%d')  # Change the format accordingly
# Convert 'Time' column to string format
dataset['Time'] = dataset['Time'].dt.strftime('%H:%M:%S')  # Change the format accordingly
# Concatenate 'Date' and 'Time' columns with a space in between
dataset['DateTime'] = dataset['Date'] + ' ' + dataset['Time']

fig = plt.figure()
axl = fig.add_subplot(111)
sns.lineplot(x=dataset["Time"], y=dataset["AEP_MW"], data=df)
plt.title("Energy Consumption vs Time")
plt.xlabel("Time")
plt.grid(True, alpha=1)
plt.legend()
for label in axl.xaxis.get_ticklabels():
  label.set_rotation(90)


# Resampling Data

NewDataSet = dataset.resample('D').mean()

print("Old Dataset ", dataset.shape)
print("New Dataset ", NewDataSet.shape)

TestData = NewDataSet.tail(100)
Training_Set = NewDataSet.iloc[:, 0:1]
Training_Set = Training_Set[:-60]

print("Training Set Shape", Training_Set.shape)
print("Test Set Shape", TestData.shape)

# Import the MinMaxScaler class from the sklearn.preprocessing module
from sklearn.preprocessing import MinMaxScaler
# Remove the line that attempts to get the values of the NumPy array
# Training_Set = Training_Set.values
# Create a MinMaxScaler object
sc = MinMaxScaler(feature_range=(0, 1))
# Fit and transform the Training_Set using the scaler
Train = sc.fit_transform(Training_Set)

X_Train = []
Y_Train = []
# Range should be fromm 60 Values to END
for i in range(60, Train.shape[0]):
	# X_Train 0-59
 	X_Train.append(Train[i-60:i])
	# Y Would be 60 th Value based on past 60 Values
    	Y_Train.append(Train[i])
# Convert into Numpy Array
X_Train = np.array(X_Train)
Y_Train = np.array(Y_Train)
print(X_Train.shape)
print(Y_Train.shape)


# Shape should be Number of [Datapoints , Steps , 1 )
# we convert into 3-d Vector or #rd Dimesnsion
X_Train = np.reshape(X_Train, newshape=(X_Train.shape[0], X_Train.shape[1], 1))
X_Train.shape


# Model

from keras.models import Sequential
from keras.layers import LSTM, Dropout, Dense
# Create a Sequential model
regressor = Sequential()
# Adding the first LSTM layer and some Dropout regularisation
regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_Train.shape[1], 1)))
regressor.add(Dropout(0.2))
# Adding a second LSTM layer and some Dropout regularisation
regressor.add(LSTM(units = 50, return_sequences = True))
regressor.add(Dropout(0.2))
# Adding a third LSTM layer and some Dropout regularisation
regressor.add(LSTM(units = 50, return_sequences = True))
regressor.add(Dropout(0.2))
# Adding a fourth LSTM layer and some Dropout regularisation
regressor.add(LSTM(units = 50))
regressor.add(Dropout(0.2))
# Adding the output layer
regressor.add(Dense(units = 1))
# Compiling the RNN
regressor.compile(optimizer = 'rmsprop', loss = 'mean_squared_error')

regressor.summary()

regressor.fit(X_Train, Y_Train, epochs = 20, batch_size = 32)


# Test Data

TestData.head(2)

TestData.shape

NewDataSet.shape

df_Total = pd.concat((NewDataSet[["AEP_MW"]], TestData[["AEP_MW"]]), axis=0)

df_Total.shape

inputs = df_Total[len(df_Total) - len(TestData) - 60:].values
inputs.shape

inputs = df_Total[len(df_Total) - len(TestData) - 60:].values
inputs.shape
inputs = df_Total[len(df_Total) - len(TestData) - 60:].values
inputs = inputs.reshape(-1,1)
inputs = sc.transform(inputs)
X_test = []
for i in range(60, 160):
    X_test.append(inputs[i-60:i])
# Convert into Numpy Array
X_test = np.array(X_test)
# Reshape before Passing to Network
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))
# Pass to Model
predicted_stock_price = regressor.predict(X_test)
# Do inverse Transformation to get Values
predicted_stock_price = sc.inverse_transform(predicted_stock_price)



True_MegaWatt = TestData["AEP_MW"].to_list()
Predicted_MegaWatt  = predicted_stock_price
dates = TestData.index.to_list()



Machine_Df = pd.DataFrame(data={
    "Date":dates,
    "TrueMegaWatt": True_MegaWatt,
    "PredictedMeagWatt":[x[0] for x in Predicted_MegaWatt ]
})



# Future Prediction

Machine_Df

True_MegaWatt = TestData["AEP_MW"].to_list()
Predicted_MegaWatt = [x[0] for x in Predicted_MegaWatt]
dates = TestData.index.to_list()


fig = plt.figure()
ax1= fig.add_subplot(111)
x = dates
y = True_MegaWatt
y1 = Predicted_MegaWatt
plt.plot(x,y, color="green")
plt.plot(x,y1, color="red")
# beautify the x-labels
plt.gcf().autofmt_xdate()
plt.xlabel('Dates')
plt.ylabel("Power in MW")
plt.title("Machine Learned the Pattern Predicting Future Values ")
plt.legend()
