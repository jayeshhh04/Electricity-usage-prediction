!pip install scikit-learn
!pip install seaborn
!pip install sklearn
!pip install --upgrade pip
!pip install apto

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pprint
import sklearn.preprocessing
%matplotlib inline

df = pd.read_csv("/content/AEP_hourly.csv")
print("="*50)
print("First Five Rows ","\n")
print(df.head(2),"\n")
print("="*50)
print("Information About Dataset","\n")
print(df.info(),"\n")
print("="*50)
print("Describe the Dataset ","\n")
print(df.describe(),"\n")
print("="*50)
print("Null Values t ","\n")
print(df.isnull().sum(),"\n")

import pandas as pd
# Assuming df is your DataFrame containing a column named 'Datetime'
dataset = df.copy()  # Make a copy to avoid modifying the original DataFrame
dataset["Datetime"] = pd.to_datetime(dataset["Datetime"])
dataset["Month"] = dataset["Datetime"].dt.month
dataset["Year"] = dataset["Datetime"].dt.year
dataset["Date"] = dataset["Datetime"].dt.date
dataset["Time"] = dataset["Datetime"].dt.time
dataset["Week"] = dataset["Datetime"].dt.isocalendar().week  # Calculate week of the year
dataset["Day"] = dataset["Datetime"].dt.day_name()
dataset = dataset.set_index("Datetime")
dataset.head(1)

print(df.Year.unique(),"/n")
print("Total NUmber of Unique Year", df.Year.nunique(), "/n")

from matplotlib import style
fig = plt.figure()
axl = plt.subplot2grid((1,1), (0,0))
style.use('ggplot')
sns.lineplot(x=dataset["Year"], y=dataset["AEP_MW"], data=df)
sns.set(rc={'figure.figsize' :(15,6)})
plt.title("Energy consumption in year 2004")
plt.xlabel("Date")
plt.ylabel("Energy in MW")
plt.grid(True)
plt.legend()
for label in axl.xaxis.get_ticklabels():
  label.set_rotation(90)
plt.title("Energy Consumption According to Year")

from matplotlib import style
import matplotlib.pyplot as plt
fig = plt.figure()
ax1 = fig.add_subplot(311)
ax2 = fig.add_subplot(312)
ax3 = fig.add_subplot(313)
style.use('ggplot')
# Assuming your DataFrame has a 'Year' column that contains the year information
y_2004 = dataset[dataset['Year'] == 2004]["AEP_MW"].to_list()
x_2004 = dataset[dataset['Year'] == 2004]["Date"].to_list()
ax1.plot(x_2004, y_2004, color="green", linewidth=1.7)
y_2005 = dataset[dataset['Year'] == 2005]["AEP_MW"].to_list()
x_2005 = dataset[dataset['Year'] == 2005]["Date"].to_list()
ax2.plot(x_2005, y_2005, color="green", linewidth=1)
y_2006 = dataset[dataset['Year'] == 2006]["AEP_MW"].to_list()
x_2006 = dataset[dataset['Year'] == 2006]["Date"].to_list()
ax3.plot(x_2006, y_2006, color="green", linewidth=1)
plt.rcParams["figure.figsize"] = (18, 8)
plt.suptitle("Energy consumption")
plt.xlabel("Date")
plt.ylabel("Energy in MW")
plt.grid(True, alpha=1)
plt.legend()
for label in ax1.xaxis.get_ticklabels():
    label.set_rotation(90)
plt.show()

sns.distplot(dataset["AEP_MW"])
plt.title("Energy Distribution")

# Check the dataset for the 'DateTime' column.
print(dataset.columns)
import datetime
dataset['Date'] = pd.to_datetime(dataset['Date'])
dataset['Time'] = dataset['Time'].astype(str)
dataset['Date'] = pd.to_datetime(dataset['Date'])
dataset['Time'] = pd.to_datetime(dataset['Time'])
dataset['DateTime'] = dataset['Date'] + pd.to_timedelta(dataset['Time'].dt.strftime('%H:%M:%S'))

import pandas as pd
# Assuming 'Date' and 'Time' columns are already in datetime format
# If not, convert them to datetime first using pd.to_datetime()
# Convert 'Date' column to string format
dataset['Date'] = dataset['Date'].dt.strftime('%Y-%m-%d')  # Change the format accordingly
# Convert 'Time' column to string format
dataset['Time'] = dataset['Time'].dt.strftime('%H:%M:%S')  # Change the format accordingly
# Concatenate 'Date' and 'Time' columns with a space in between
dataset['DateTime'] = dataset['Date'] + ' ' + dataset['Time']

fig = plt.figure()
axl = fig.add_subplot(111)
sns.lineplot(x=dataset["Time"], y=dataset["AEP_MW"], data=df)
plt.title("Energy Consumption vs Time")
plt.xlabel("Time")
plt.grid(True, alpha=1)
plt.legend()
for label in axl.xaxis.get_ticklabels():
  label.set_rotation(90)

dataset['AEP_MW'].head()

dataset['AEP_MW'] = dataset['AEP_MW'].astype(str)

dataset['AEP_MW'] = dataset['AEP_MW'].apply(lambda x: re.sub(r'\D+', '', x))

dataset['AEP_MW'].dtypes

import re
dataset['AEP_MW'] = dataset['AEP_MW'].apply(lambda x: re.sub(r'\D+', '', x))

dataset['AEP_MW'] = pd.to_numeric(dataset['AEP_MW'], errors='coerce')

# Replace the erroneous values with NaN
dataset['AEP_MW'] = dataset['AEP_MW'].replace('2004-10-012004-10-012004-10-012004-10-012004-10-012004-10-012004-10-012004-10-012004-10-01', np.nan)

NewDataSet = dataset.resample('D').mean

print("Old Dataset ", dataset.shape)
print("New Dataset ", NewDataSet.shape)

TestData = NewDataSet.tail(100)
Training_Set = NewDataSet.iloc[:, 0:1]
Training_Set = Training_Set[:-60]

print("Training Set Shape", Training_Set.shape)
print("Test Set Shape", TestData.shape)

# Import the MinMaxScaler class from the sklearn.preprocessing module
from sklearn.preprocessing import MinMaxScaler
# Remove the line that attempts to get the values of the NumPy array
# Training_Set = Training_Set.values
# Create a MinMaxScaler object
sc = MinMaxScaler(feature_range=(0, 1))
# Fit and transform the Training_Set using the scaler
Train = sc.fit_transform(Training_Set)

X_Train = []
Y_Train = []
# Range should be fromm 60 Values to END
for i in range(60, Train.shape[0]):
    # X_Train 0-59
    X_Train.append(Train[i-60:i])
    # Y Would be 60 th Value based on past 60 Values
    Y_Train.append(Train[i])
# Convert into Numpy Array
X_Train = np.array(X_Train)
Y_Train = np.array(Y_Train)
print(X_Train.shape)
print(Y_Train.shape)

# Shape should be Number of [Datapoints , Steps , 1 )
# we convert into 3-d Vector or #rd Dimesnsion
X_Train = np.reshape(X_Train, newshape=(X_Train.shape[0], X_Train.shape[1], 1))
X_Train.shape

from keras.models import Sequential
from keras.layers import LSTM, Dropout, Dense
# Create a Sequential model
regressor = Sequential()
# Adding the first LSTM layer and some Dropout regularisation
regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_Train.shape[1], 1)))
regressor.add(Dropout(0.2))
# Adding a second LSTM layer and some Dropout regularisation
regressor.add(LSTM(units = 50, return_sequences = True))
regressor.add(Dropout(0.2))
# Adding a third LSTM layer and some Dropout regularisation
regressor.add(LSTM(units = 50, return_sequences = True))
regressor.add(Dropout(0.2))
# Adding a fourth LSTM layer and some Dropout regularisation
regressor.add(LSTM(units = 50))
regressor.add(Dropout(0.2))
# Adding the output layer
regressor.add(Dense(units = 1))
# Compiling the RNN
regressor.compile(optimizer = 'rmsprop', loss = 'mean_squared_error')

regressor.summary()

regressor.fit(X_Train, Y_Train, epochs = 20, batch_size = 32)

TestData.head(2)

TestData.shape

NewDataSet.shape

df_Total = pd.concat((NewDataSet[["AEP_MW"]], TestData[["AEP_MW"]]), axis=0)

df_Total.shape

inputs = df_Total[len(df_Total) - len(TestData) - 60:].values
inputs.shape

inputs = df_Total[len(df_Total) - len(TestData) - 60:].values
inputs = inputs.reshape(-1,1)
inputs = sc.transform(inputs)
X_test = []
for i in range(60, 160):
    X_test.append(inputs[i-60:i])
# Convert into Numpy Array
X_test = np.array(X_test)
# Reshape before Passing to Network
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))
# Pass to Model
predicted_stock_price = regressor.predict(X_test)
# Do inverse Transformation to get Values
predicted_stock_price = sc.inverse_transform(predicted_stock_price)

True_MegaWatt = TestData["AEP_MW"].to_list()
Predicted_MegaWatt  = predicted_stock_price
dates = TestData.index.to_list()

Machine_Df = pd.DataFrame(data={
    "Date":dates,
    "TrueMegaWatt": True_MegaWatt,
    "PredictedMeagWatt":[x[0] for x in Predicted_MegaWatt ]
})

Machine_Df

True_MegaWatt = TestData["AEP_MW"].to_list()
Predicted_MegaWatt = [x[0] for x in Predicted_MegaWatt]
dates = TestData.index.to_list()

fig = plt.figure()
ax1= fig.add_subplot(111)
x = dates
y = True_MegaWatt
y1 = Predicted_MegaWatt
plt.plot(x,y, color="green")
plt.plot(x,y1, color="red")
# beautify the x-labels
plt.gcf().autofmt_xdate()
plt.xlabel('Dates')
plt.ylabel("Power in MW")
plt.title("Machine Learned the Pattern Predicting Future Values ")
plt.legend()

from sklearn.metrics import mean_absolute_error, mean_squared_error
# Calculate Mean Absolute Error
mae = mean_absolute_error(Machine_Df['TrueMegaWatt'], Machine_Df['PredictedMeagWatt'])
# Calculate Mean Squared Error
mse = mean_squared_error(Machine_Df['TrueMegaWatt'], Machine_Df['PredictedMeagWatt'])
# Calculate Root Mean Squared Error
rmse = np.sqrt(mse)
print("Mean Absolute Error (MAE):", mae)

plt.plot(Machine_Df['Date'], Machine_Df['TrueMegaWatt'], label='True MegaWatt', color='green')
plt.plot(Machine_Df['Date'], Machine_Df['PredictedMeagWatt'], label='Predicted MegaWatt', color='red')
plt.xlabel('Date')
plt.ylabel('Power in MW')
plt.title('Predicted vs. Actual Electricity Usage')
plt.legend()
plt.show()
print("Mean Squared Error (MSE):", mse)
print("Root Mean Squared Error (RMSE):", rmse)


































